{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT-Relation-Extractor.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDkoMDM21M-R"
      },
      "source": [
        "!pip install pandas\n",
        "!pip install numpy\n",
        "!pip install transformers\n",
        "!pip install torch torchvision\n",
        "!pip install sentencepiece"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MX0Qhns01_LR"
      },
      "source": [
        "Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4ICjFN_2Cr4"
      },
      "source": [
        "import json\n",
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader, TensorDataset, RandomSampler, SequentialSampler\n",
        "from tqdm import tqdm\n",
        "from transformers import BertTokenizer, RobertaTokenizer, RobertaForSequenceClassification, AdamW, BertForSequenceClassification\n",
        "from transformers import DistilBertForTokenClassification, Trainer, TrainingArguments\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "import statistics\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-tkvP2J414E"
      },
      "source": [
        "Read Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxGEdhrH43nP"
      },
      "source": [
        "def read_data_entity_marker(tags):\n",
        "    context_text = []\n",
        "    context_tags = []\n",
        "\n",
        "    for tagg in tags:\n",
        "        context_text.append(tagg[1])\n",
        "    return context_text\n",
        "\n",
        "\n",
        "def read_data_tag_sentence(texts, tags):\n",
        "    context_text = []\n",
        "    context_tags = []\n",
        "\n",
        "    for textt in texts:\n",
        "        for tagg in tags:\n",
        "            if int(textt[0]) == int(tagg[0]):\n",
        "                context_text.append(textt[1])\n",
        "                context_tags.append(tagg[1])\n",
        "            else:\n",
        "                continue\n",
        "    return context_text, context_tags\n",
        "\n",
        "\n",
        "def read_labels(dataa):\n",
        "    labels = []\n",
        "    count = 0\n",
        "    for dat in dataa:\n",
        "        for ent in dat[\"entities\"]:\n",
        "            labels.append(int(ent[\"label\"]))\n",
        "            count += 1\n",
        "    return labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2pGiXUk482z"
      },
      "source": [
        "Tokenize Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71aAKBS35GoT"
      },
      "source": [
        "def tokenizeData_entity_marker(tokenizer, text, max_length=256):\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "\n",
        "    for tx in text:\n",
        "        tokenizedData = tokenizer.encode_plus(tx, max_length=max_length,\n",
        "                                              padding='max_length', truncation=\"longest_first\")\n",
        "        tokenizedQP = tokenizedData[\"input_ids\"]\n",
        "        attentionMask = tokenizedData[\"attention_mask\"]\n",
        "\n",
        "        input_ids.append(tokenizedQP)\n",
        "        attention_masks.append(attentionMask)\n",
        "\n",
        "    return np.array(input_ids), np.array(attention_masks)\n",
        "\n",
        "def tokenizeData_tag_sentence(tokenizer, text, tags, max_length=256):\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "\n",
        "    for tx, tg in zip(text, tags):\n",
        "        tokenizedData = tokenizer.encode_plus(tx, tg, max_length=max_length,\n",
        "                                              padding='max_length', truncation=\"longest_first\")\n",
        "        tokenizedQP = tokenizedData[\"input_ids\"]\n",
        "        attentionMask = tokenizedData[\"attention_mask\"]\n",
        "\n",
        "        input_ids.append(tokenizedQP)\n",
        "        attention_masks.append(attentionMask)\n",
        "\n",
        "    return np.array(input_ids), np.array(attention_masks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCUC-qBz5LbW"
      },
      "source": [
        "Data Loaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrw3DsHi5M7-"
      },
      "source": [
        "def buildDataLoaders(batchSize, trainFeatures, testFeatures):\n",
        "    trainTensors = [torch.tensor(feature, dtype=torch.long) for feature in trainFeatures]\n",
        "    testTensors = [torch.tensor(feature, dtype=torch.long) for feature in testFeatures]\n",
        "\n",
        "    trainDataset = TensorDataset(*trainTensors)\n",
        "    testDataset = TensorDataset(*testTensors)\n",
        "\n",
        "    trainSampler = RandomSampler(trainDataset)\n",
        "    testSampler = SequentialSampler(testDataset)\n",
        "\n",
        "    trainDataloader = DataLoader(trainDataset, sampler=trainSampler, batch_size=batchSize)\n",
        "    testDataloader = DataLoader(testDataset, sampler=testSampler, batch_size=batchSize)\n",
        "\n",
        "    return trainDataloader, testDataloader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7bhFaRg5V1x"
      },
      "source": [
        "Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWzS1DWN5XAv"
      },
      "source": [
        "def train(numEpochs, gradSteps, model, optimizer, trainDataLoader):\n",
        "    trainLossHistory = []\n",
        "\n",
        "    for _ in tqdm(range(numEpochs), desc=\"Training Epoch's\"):\n",
        "\n",
        "        # Train the model for fine-tuning\n",
        "        epochTrainLoss = 0  # Cumulative loss\n",
        "        model.train()\n",
        "        model.zero_grad()\n",
        "\n",
        "        for step, batch in enumerate(trainDataLoader):\n",
        "            input_ids = batch[0].to(device)\n",
        "            attention_masks = batch[1].to(device)\n",
        "            label = batch[2].to(device)\n",
        "            outputs = model(input_ids, token_type_ids=None, attention_mask=attention_masks, labels=label)\n",
        "\n",
        "            loss = outputs[0]\n",
        "            loss = loss / gradSteps\n",
        "            epochTrainLoss += loss.item()\n",
        "            loss.backward()\n",
        "\n",
        "            if (step + 1) % gradSteps == 0:  # Gradient accumulation is over\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)  # Clipping gradients\n",
        "                optimizer.step()\n",
        "                model.zero_grad()\n",
        "\n",
        "        epochTrainLoss = epochTrainLoss / len(trainDataLoader)\n",
        "        trainLossHistory.append(epochTrainLoss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9oDotOtQ5aze"
      },
      "source": [
        "Predict and Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPfE_QKd5fgm"
      },
      "source": [
        "def predict_tag_sentence(tokenizer, model, text, tag, max_length=256):\n",
        "    sequence = tokenizer.encode_plus(tag, text, max_length=max_length,\n",
        "                                     padding='max_length', truncation=\"longest_first\"\n",
        "                                     , return_tensors=\"pt\")['input_ids'].to(device)\n",
        "\n",
        "    logits = model(sequence)[0]\n",
        "    probabilities = torch.softmax(logits, dim=1).detach().cpu().tolist()[0]\n",
        "    if probabilities[1] > 0.5:\n",
        "        return 1\n",
        "    return 0\n",
        "\n",
        "def predict_entity_marker(tokenizer, model, text, max_length=256):\n",
        "    sequence = tokenizer.encode_plus(text, max_length=max_length,\n",
        "                                     padding='max_length', truncation=\"longest_first\"\n",
        "                                     , return_tensors=\"pt\")['input_ids'].to(device)\n",
        "\n",
        "    logits = model(sequence)[0]\n",
        "    probabilities = torch.softmax(logits, dim=1).detach().cpu().tolist()[0]\n",
        "    if probabilities[1] > 0.5:\n",
        "        return 1\n",
        "    return 0\n",
        "\n",
        "\n",
        "def evaluate(pred_labels, test_labels):\n",
        "    pred_labels1 = np.array_split(pred_labels, 5)\n",
        "    test_labels1 = np.array_split(test_labels, 5)\n",
        "    accuracy = []\n",
        "    f1 = []\n",
        "    for test, pred in zip(test_labels1, pred_labels1):\n",
        "        accuracy.append(accuracy_score(test, pred))\n",
        "        f1.append(f1_score(test, pred, average=\"weighted\"))\n",
        "\n",
        "    print(\"Accuracy: \" + str(sum(accuracy) / len(accuracy)))\n",
        "    print(\"Standard Deviation: \" + str(statistics.stdev(accuracy)))\n",
        "\n",
        "    print(\"F1 Score: \" + str(sum(f1) / len(f1)))\n",
        "    print(\"Standard Deviation: \" + str(statistics.stdev(f1)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6n12RnuT5lG8"
      },
      "source": [
        "BERT Entity Marker"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NK8dH8Gx5muP"
      },
      "source": [
        "def bert_entity_marker_a(file):\n",
        "    with open(file) as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    text_list = []\n",
        "    tag_list = []\n",
        "\n",
        "    for d in data:\n",
        "        for ent in d[\"entities\"]:\n",
        "            tag_list.append(\n",
        "                [d[\"id\"],\n",
        "                 d[\"text\"].replace(ent[\"arg1\"] + \" \", \"[e]\" + ent[\"arg1\"] + \"[\\e]\").replace(\" \" + ent[\"arg2\"] + \" \",\n",
        "                                                                                            \"[e]\" + ent[\n",
        "                                                                                                \"arg2\"] + \"[\\e]\").strip(\n",
        "                     \"\\n\")])\n",
        "\n",
        "    text = read_data_entity_marker(tag_list)\n",
        "    labels = read_labels(data)\n",
        "\n",
        "    sentences = []\n",
        "    args1 = []\n",
        "    args2 = []\n",
        "\n",
        "    for d in data:\n",
        "      sentences.append([d[\"id\"], d[\"text\"]])\n",
        "      for ent in d[\"entities\"]:\n",
        "        args1.append([d[\"id\"], ent[\"arg1\"]])\n",
        "        args2.append([d[\"id\"], ent[\"arg2\"]])\n",
        "\n",
        "    train_texts, test_texts, train_labels, test_labels = train_test_split(text, labels, test_size=.2)\n",
        "\n",
        "    train_arg1, test_arg1, train_arg2, test_arg2 = train_test_split(args1, args2, test_size=.2)\n",
        "\n",
        "    tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
        "    train_ids, train_attn = tokenizeData_entity_marker(tokenizer, train_texts)\n",
        "    test_ids, test_attn = tokenizeData_entity_marker(tokenizer, test_texts)\n",
        "\n",
        "    trainFeatures = (train_ids, train_attn, train_labels)\n",
        "    testFeatures = (test_ids, test_attn)\n",
        "\n",
        "    trainDataLoader, testDataLoader = buildDataLoaders(8, trainFeatures, testFeatures)\n",
        "\n",
        "    model = BertForSequenceClassification.from_pretrained('bert-base-cased').to(device)\n",
        "    optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "\n",
        "    train(3, 3, model, optimizer, trainDataLoader)\n",
        "\n",
        "    pred_labels = []\n",
        "    for text in test_texts:\n",
        "        pred_labels.append(predict_entity_marker(tokenizer, model, text))\n",
        "\n",
        "    evaluate(pred_labels, test_labels)\n",
        "\n",
        "    pred_args = []\n",
        "    for arg1, arg2, label in zip(test_arg1, test_arg2, pred_labels):\n",
        "      pred_args.append({\"arg1\": arg1[1], \"arg2\": arg2[1], \"label\": label})\n",
        "    \n",
        "    with open('predictions.json', 'w') as f:\n",
        "      json.dump(pred_args, f, indent=4)\n",
        "\n",
        "\n",
        "def bert_entity_marker_b(file):\n",
        "    with open(file) as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    text_list = []\n",
        "    tag_list = []\n",
        "\n",
        "    for d in data:\n",
        "        for ent in d[\"entities\"]:\n",
        "            tag_list.append(\n",
        "                [d[\"id\"],\n",
        "                 d[\"text\"].replace(ent[\"arg1\"] + \" \", \"[e] \" + ent[\"arg1\"] + \" [\\e]\").replace(\" \" + ent[\"arg2\"] + \" \",\n",
        "                                                                                            \"[e] \" + ent[\n",
        "                                                                                                \"arg2\"] + \" [\\e]\").strip(\n",
        "                     \"\\n\")])\n",
        "\n",
        "    text = read_data_entity_marker(tag_list)\n",
        "    labels = read_labels(data)\n",
        "\n",
        "    sentences = []\n",
        "    args1 = []\n",
        "    args2 = []\n",
        "\n",
        "    for d in data:\n",
        "      sentences.append([d[\"id\"], d[\"text\"]])\n",
        "      for ent in d[\"entities\"]:\n",
        "        args1.append([d[\"id\"], ent[\"arg1\"]])\n",
        "        args2.append([d[\"id\"], ent[\"arg2\"]])\n",
        "\n",
        "    train_texts, test_texts, train_labels, test_labels = train_test_split(text, labels, test_size=.2)\n",
        "\n",
        "    train_arg1, test_arg1, train_arg2, test_arg2 = train_test_split(args1, args2, test_size=.2)\n",
        "\n",
        "    tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
        "    train_ids, train_attn = tokenizeData_entity_marker(tokenizer, train_texts)\n",
        "    test_ids, test_attn = tokenizeData_entity_marker(tokenizer, test_texts)\n",
        "\n",
        "    trainFeatures = (train_ids, train_attn, train_labels)\n",
        "    testFeatures = (test_ids, test_attn)\n",
        "\n",
        "    trainDataLoader, testDataLoader = buildDataLoaders(8, trainFeatures, testFeatures)\n",
        "\n",
        "    model = BertForSequenceClassification.from_pretrained('bert-base-cased').to(device)\n",
        "    optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "\n",
        "    train(3, 3, model, optimizer, trainDataLoader)\n",
        "\n",
        "    pred_labels = []\n",
        "    for text in test_texts:\n",
        "        pred_labels.append(predict_entity_marker(tokenizer, model, text))\n",
        "\n",
        "    evaluate(pred_labels, test_labels)\n",
        "\n",
        "    pred_args = []\n",
        "    for arg1, arg2, label in zip(test_arg1, test_arg2, pred_labels):\n",
        "      pred_args.append({\"arg1\": arg1[1], \"arg2\": arg2[1], \"label\": label})\n",
        "    \n",
        "    with open('predictions.json', 'w') as f:\n",
        "      json.dump(pred_args, f, indent=4)\n",
        "\n",
        "\n",
        "def bert_entity_marker_c(file):\n",
        "    with open(file) as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    text_list = []\n",
        "    tag_list = []\n",
        "\n",
        "    for d in data:\n",
        "        for ent in d[\"entities\"]:\n",
        "            tag_list.append(\n",
        "                [d[\"id\"],\n",
        "                 d[\"text\"].replace(ent[\"arg1\"] + \" \", \"ENTITY1\" + ent[\"arg1\"]).replace(\" \" + ent[\"arg2\"] + \" \",\n",
        "                                                                                            \"ENTITY2\" + ent[\n",
        "                                                                                                \"arg2\"]).strip(\n",
        "                     \"\\n\")])\n",
        "\n",
        "    text = read_data_entity_marker(tag_list)\n",
        "    labels = read_labels(data)\n",
        "\n",
        "    sentences = []\n",
        "    args1 = []\n",
        "    args2 = []\n",
        "\n",
        "    for d in data:\n",
        "      sentences.append([d[\"id\"], d[\"text\"]])\n",
        "      for ent in d[\"entities\"]:\n",
        "        args1.append([d[\"id\"], ent[\"arg1\"]])\n",
        "        args2.append([d[\"id\"], ent[\"arg2\"]])\n",
        "\n",
        "    train_texts, test_texts, train_labels, test_labels = train_test_split(text, labels, test_size=.2)\n",
        "\n",
        "    train_arg1, test_arg1, train_arg2, test_arg2 = train_test_split(args1, args2, test_size=.2)\n",
        "\n",
        "    tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
        "    train_ids, train_attn = tokenizeData_entity_marker(tokenizer, train_texts)\n",
        "    test_ids, test_attn = tokenizeData_entity_marker(tokenizer, test_texts)\n",
        "\n",
        "    trainFeatures = (train_ids, train_attn, train_labels)\n",
        "    testFeatures = (test_ids, test_attn)\n",
        "\n",
        "    trainDataLoader, testDataLoader = buildDataLoaders(8, trainFeatures, testFeatures)\n",
        "\n",
        "    model = BertForSequenceClassification.from_pretrained('bert-base-cased').to(device)\n",
        "    optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "\n",
        "    train(3, 3, model, optimizer, trainDataLoader)\n",
        "\n",
        "    pred_labels = []\n",
        "    for text in test_texts:\n",
        "        pred_labels.append(predict_entity_marker(tokenizer, model, text))\n",
        "\n",
        "    evaluate(pred_labels, test_labels)\n",
        "\n",
        "    pred_args = []\n",
        "    for arg1, arg2, label in zip(test_arg1, test_arg2, pred_labels):\n",
        "      pred_args.append({\"arg1\": arg1[1], \"arg2\": arg2[1], \"label\": label})\n",
        "    \n",
        "    with open('predictions.json', 'w') as f:\n",
        "      json.dump(pred_args, f, indent=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7MbiMw176RkY"
      },
      "source": [
        "BERT Tag Sentence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9bAcpkQ6TnY"
      },
      "source": [
        "def bert_tag_sentence(file):\n",
        "    with open(file) as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    text_list = []\n",
        "    tag_list = []\n",
        "\n",
        "    for d in data:\n",
        "        text_list.append([d[\"id\"], d[\"text\"].strip(\"\\n\")])\n",
        "        for ent in d[\"entities\"]:\n",
        "            tag_list.append([d[\"id\"], d[\"text\"].replace(ent[\"arg1\"] + \" \", \"ENTITY1 \").replace(\" \" + ent[\"arg2\"] + \" \",\n",
        "                                                                                               \" ENTITY2 \").strip(\n",
        "                \"\\n\")])\n",
        "\n",
        "    text, tags = read_data_tag_sentence(text_list, tag_list)\n",
        "    labels = read_labels(data)\n",
        "\n",
        "    sentences = []\n",
        "    args1 = []\n",
        "    args2 = []\n",
        "\n",
        "    for d in data:\n",
        "      sentences.append([d[\"id\"], d[\"text\"]])\n",
        "      for ent in d[\"entities\"]:\n",
        "        args1.append([d[\"id\"], ent[\"arg1\"]])\n",
        "        args2.append([d[\"id\"], ent[\"arg2\"]])\n",
        "\n",
        "    train_texts, test_texts, train_tags, test_tags, train_labels, test_labels = train_test_split(text, tags,\n",
        "                                                                                                 labels, test_size=.2)\n",
        "    \n",
        "    train_arg1, test_arg1, train_arg2, test_arg2 = train_test_split(args1, args2, test_size=.2)\n",
        "\n",
        "    tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
        "    train_ids, train_attn = tokenizeData_tag_sentence(tokenizer, train_texts, train_tags)\n",
        "    test_ids, test_attn = tokenizeData_tag_sentence(tokenizer, test_texts, test_tags)\n",
        "\n",
        "    trainFeatures = (train_ids, train_attn, train_labels)\n",
        "    testFeatures = (test_ids, test_attn)\n",
        "\n",
        "    trainDataLoader, testDataLoader = buildDataLoaders(8, trainFeatures, testFeatures)\n",
        "\n",
        "    model = BertForSequenceClassification.from_pretrained('bert-base-cased').to(device)\n",
        "    optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "\n",
        "    train(3, 3, model, optimizer, trainDataLoader)\n",
        "\n",
        "    pred_labels = []\n",
        "    for text, tags in zip(test_texts, test_tags):\n",
        "        pred_labels.append(predict_tag_sentence(tokenizer, model, text, tags))\n",
        "\n",
        "    evaluate(pred_labels, test_labels)\n",
        "\n",
        "    pred_args = []\n",
        "    for arg1, arg2, label in zip(test_arg1, test_arg2, pred_labels):\n",
        "      pred_args.append({\"arg1\": arg1[1], \"arg2\": arg2[1], \"label\": label})\n",
        "    \n",
        "    with open('predictions.json', 'w') as f:\n",
        "      json.dump(pred_args, f, indent=4)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7GP0B466n4w"
      },
      "source": [
        "Roberta Entity Marker"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9Xg2bF86qTX"
      },
      "source": [
        "def roberta_entity_marker_a(file):\n",
        "    with open(file) as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    text_list = []\n",
        "    tag_list = []\n",
        "\n",
        "    for d in data:\n",
        "        for ent in d[\"entities\"]:\n",
        "            tag_list.append(\n",
        "                [d[\"id\"],\n",
        "                 d[\"text\"].replace(ent[\"arg1\"] + \" \", \"[e]\" + ent[\"arg1\"] + \"[\\e]\").replace(\" \" + ent[\"arg2\"] + \" \",\n",
        "                                                                                            \"[e]\" + ent[\n",
        "                                                                                                \"arg2\"] + \"[\\e]\").strip(\n",
        "                     \"\\n\")])\n",
        "\n",
        "    text = read_data_entity_marker(tag_list)\n",
        "    labels = read_labels(data)\n",
        "\n",
        "    sentences = []\n",
        "    args1 = []\n",
        "    args2 = []\n",
        "\n",
        "    for d in data:\n",
        "      sentences.append([d[\"id\"], d[\"text\"]])\n",
        "      for ent in d[\"entities\"]:\n",
        "        args1.append([d[\"id\"], ent[\"arg1\"]])\n",
        "        args2.append([d[\"id\"], ent[\"arg2\"]])\n",
        "\n",
        "    train_texts, test_texts, train_labels, test_labels = train_test_split(text, labels, test_size=.2)\n",
        "\n",
        "    train_arg1, test_arg1, train_arg2, test_arg2 = train_test_split(args1, args2, test_size=.2)\n",
        "\n",
        "    tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
        "    train_ids, train_attn = tokenizeData_entity_marker(tokenizer, train_texts)\n",
        "    test_ids, test_attn = tokenizeData_entity_marker(tokenizer, test_texts)\n",
        "\n",
        "    trainFeatures = (train_ids, train_attn, train_labels)\n",
        "    testFeatures = (test_ids, test_attn)\n",
        "\n",
        "    trainDataLoader, testDataLoader = buildDataLoaders(8, trainFeatures, testFeatures)\n",
        "\n",
        "    model = RobertaForSequenceClassification.from_pretrained('roberta-base').to(device)\n",
        "    optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "\n",
        "    train(3, 3, model, optimizer, trainDataLoader)\n",
        "\n",
        "    pred_labels = []\n",
        "    for text in test_texts:\n",
        "        pred_labels.append(predict_entity_marker(tokenizer, model, text))\n",
        "\n",
        "    evaluate(pred_labels, test_labels)\n",
        "\n",
        "    pred_args = []\n",
        "    for arg1, arg2, label in zip(test_arg1, test_arg2, pred_labels):\n",
        "      pred_args.append({\"arg1\": arg1[1], \"arg2\": arg2[1], \"label\": label})\n",
        "    \n",
        "    with open('predictions.json', 'w') as f:\n",
        "      json.dump(pred_args, f, indent=4)\n",
        "\n",
        "\n",
        "def roberta_entity_marker_b(file):\n",
        "    with open(file) as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    text_list = []\n",
        "    tag_list = []\n",
        "\n",
        "    for d in data:\n",
        "        for ent in d[\"entities\"]:\n",
        "            tag_list.append(\n",
        "                [d[\"id\"],\n",
        "                 d[\"text\"].replace(ent[\"arg1\"] + \" \", \"[e] \" + ent[\"arg1\"] + \" [\\e]\").replace(\" \" + ent[\"arg2\"] + \" \",\n",
        "                                                                                            \"[e] \" + ent[\n",
        "                                                                                                \"arg2\"] + \" [\\e]\").strip(\n",
        "                     \"\\n\")])\n",
        "\n",
        "    text = read_data_entity_marker(tag_list)\n",
        "    labels = read_labels(data)\n",
        "\n",
        "    sentences = []\n",
        "    args1 = []\n",
        "    args2 = []\n",
        "\n",
        "    for d in data:\n",
        "      sentences.append([d[\"id\"], d[\"text\"]])\n",
        "      for ent in d[\"entities\"]:\n",
        "        args1.append([d[\"id\"], ent[\"arg1\"]])\n",
        "        args2.append([d[\"id\"], ent[\"arg2\"]])\n",
        "\n",
        "    train_texts, test_texts, train_labels, test_labels = train_test_split(text, labels, test_size=.2)\n",
        "\n",
        "    train_arg1, test_arg1, train_arg2, test_arg2 = train_test_split(args1, args2, test_size=.2)\n",
        "\n",
        "    tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
        "    train_ids, train_attn = tokenizeData_entity_marker(tokenizer, train_texts)\n",
        "    test_ids, test_attn = tokenizeData_entity_marker(tokenizer, test_texts)\n",
        "\n",
        "    trainFeatures = (train_ids, train_attn, train_labels)\n",
        "    testFeatures = (test_ids, test_attn)\n",
        "\n",
        "    trainDataLoader, testDataLoader = Read.buildDataLoaders(8, trainFeatures, testFeatures)\n",
        "\n",
        "    model = RobertaForSequenceClassification.from_pretrained('roberta-base').to(device)\n",
        "    optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "\n",
        "    train(3, 3, model, optimizer, trainDataLoader)\n",
        "\n",
        "    pred_labels = []\n",
        "    for text in test_texts:\n",
        "        pred_labels.append(predict_entity_marker(tokenizer, model, text))\n",
        "\n",
        "    evaluate(pred_labels, test_labels)\n",
        "\n",
        "    pred_args = []\n",
        "    for arg1, arg2, label in zip(test_arg1, test_arg2, pred_labels):\n",
        "      pred_args.append({\"arg1\": arg1[1], \"arg2\": arg2[1], \"label\": label})\n",
        "    \n",
        "    with open('predictions.json', 'w') as f:\n",
        "      json.dump(pred_args, f, indent=4)\n",
        "\n",
        "\n",
        "def roberta_entity_marker_c(file):\n",
        "    with open(file) as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    text_list = []\n",
        "    tag_list = []\n",
        "\n",
        "    for d in data:\n",
        "        for ent in d[\"entities\"]:\n",
        "            tag_list.append(\n",
        "                [d[\"id\"],\n",
        "                 d[\"text\"].replace(ent[\"arg1\"] + \" \", \"ENTITY1\" + ent[\"arg1\"]).replace(\" \" + ent[\"arg2\"] + \" \",\n",
        "                                                                                            \"ENTITY2\" + ent[\n",
        "                                                                                                \"arg2\"]).strip(\n",
        "                     \"\\n\")])\n",
        "\n",
        "    text = read_data_entity_marker(tag_list)\n",
        "    labels = read_labels(data)\n",
        "\n",
        "    sentences = []\n",
        "    args1 = []\n",
        "    args2 = []\n",
        "\n",
        "    for d in data:\n",
        "      sentences.append([d[\"id\"], d[\"text\"]])\n",
        "      for ent in d[\"entities\"]:\n",
        "        args1.append([d[\"id\"], ent[\"arg1\"]])\n",
        "        args2.append([d[\"id\"], ent[\"arg2\"]])\n",
        "\n",
        "    train_texts, test_texts, train_labels, test_labels = train_test_split(text, labels, test_size=.2)\n",
        "\n",
        "    train_arg1, test_arg1, train_arg2, test_arg2 = train_test_split(args1, args2, test_size=.2)\n",
        "\n",
        "    tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
        "    train_ids, train_attn = tokenizeData_entity_marker(tokenizer, train_texts)\n",
        "    test_ids, test_attn = tokenizeData_entity_marker(tokenizer, test_texts)\n",
        "\n",
        "    trainFeatures = (train_ids, train_attn, train_labels)\n",
        "    testFeatures = (test_ids, test_attn)\n",
        "\n",
        "    trainDataLoader, testDataLoader = buildDataLoaders(8, trainFeatures, testFeatures)\n",
        "\n",
        "    model = RobertaForSequenceClassification.from_pretrained('roberta-base').to(device)\n",
        "    optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "\n",
        "    train(3, 3, model, optimizer, trainDataLoader)\n",
        "\n",
        "    pred_labels = []\n",
        "    for text in test_texts:\n",
        "        pred_labels.append(predict_entity_marker(tokenizer, model, text))\n",
        "\n",
        "    evaluate(pred_labels, test_labels)\n",
        "\n",
        "    pred_args = []\n",
        "    for arg1, arg2, label in zip(test_arg1, test_arg2, pred_labels):\n",
        "      pred_args.append({\"arg1\": arg1[1], \"arg2\": arg2[1], \"label\": label})\n",
        "    \n",
        "    with open('predictions.json', 'w') as f:\n",
        "      json.dump(pred_args, f, indent=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anoHLM5V7Dk6"
      },
      "source": [
        "Roberta Tag Sentence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55nguhV_7FH7"
      },
      "source": [
        "def roberta_tag_sentence(file):\n",
        "    with open(file) as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    text_list = []\n",
        "    tag_list = []\n",
        "\n",
        "    for d in data:\n",
        "        text_list.append([d[\"id\"], d[\"text\"].strip(\"\\n\")])\n",
        "        for ent in d[\"entities\"]:\n",
        "            tag_list.append([d[\"id\"], d[\"text\"].replace(ent[\"arg1\"] + \" \", \"ENTITY1 \").replace(\" \" + ent[\"arg2\"] + \" \",\n",
        "                                                                                               \" ENTITY2 \").strip(\n",
        "                \"\\n\")])\n",
        "\n",
        "    text, tags = read_data_tag_sentence(text_list, tag_list)\n",
        "    labels = read_labels(data)\n",
        "\n",
        "    sentences = []\n",
        "    args1 = []\n",
        "    args2 = []\n",
        "\n",
        "    for d in data:\n",
        "      sentences.append([d[\"id\"], d[\"text\"]])\n",
        "      for ent in d[\"entities\"]:\n",
        "        args1.append([d[\"id\"], ent[\"arg1\"]])\n",
        "        args2.append([d[\"id\"], ent[\"arg2\"]])\n",
        "\n",
        "    train_texts, test_texts, train_tags, test_tags, train_labels, test_labels = train_test_split(text, tags,\n",
        "                                                                                                 labels, test_size=.2)\n",
        "    \n",
        "    train_arg1, test_arg1, train_arg2, test_arg2 = train_test_split(args1, args2, test_size=.2)\n",
        "\n",
        "    tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
        "    train_ids, train_attn = tokenizeData_tag_sentence(tokenizer, train_texts, train_tags)\n",
        "    test_ids, test_attn = tokenizeData_tag_sentence(tokenizer, test_texts, test_tags)\n",
        "\n",
        "    trainFeatures = (train_ids, train_attn, train_labels)\n",
        "    testFeatures = (test_ids, test_attn)\n",
        "\n",
        "    trainDataLoader, testDataLoader = buildDataLoaders(8, trainFeatures, testFeatures)\n",
        "\n",
        "    model = RobertaForSequenceClassification.from_pretrained('roberta-base').to(device)\n",
        "    optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "\n",
        "    train(3, 3, model, optimizer, trainDataLoader)\n",
        "\n",
        "    pred_labels = []\n",
        "    for text, tags in zip(test_texts, test_tags):\n",
        "        pred_labels.append(predict_tag_sentence(tokenizer, model, text, tags))\n",
        "\n",
        "    evaluate(pred_labels, test_labels)\n",
        "\n",
        "    pred_args = []\n",
        "    for arg1, arg2, label in zip(test_arg1, test_arg2, pred_labels):\n",
        "      pred_args.append({\"arg1\": arg1[1], \"arg2\": arg2[1], \"label\": label})\n",
        "    \n",
        "    with open('predictions.json', 'w') as f:\n",
        "      json.dump(pred_args, f, indent=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjWNUWOG7XIZ"
      },
      "source": [
        "Main"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wlp34kMD7X95"
      },
      "source": [
        "if __name__ == '__main__':\n",
        "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "    print(device)\n",
        "\n",
        "    file = input(\"Enter Dataset: \")\n",
        "\n",
        "    print(\"Select a model to train:\")\n",
        "    print(\"1.) BERT\")\n",
        "    print(\"2.) RoBERTa\")\n",
        "\n",
        "    model = int(input())\n",
        "\n",
        "    if model == 1:\n",
        "        print(\"Select a method:\")\n",
        "        print(\"1.) Entity Marker A\")\n",
        "        print(\"2.) Entity Marker B\")\n",
        "        print(\"3.) Entity Marker C\")\n",
        "        print(\"4.) Tag Sentence\")\n",
        "\n",
        "        method = int(input())\n",
        "\n",
        "        if method == 1:\n",
        "            bert_entity_marker_a(file)\n",
        "        elif method == 2:\n",
        "            bert_entity_marker_b(file)\n",
        "        elif method == 3:\n",
        "            bert_entity_marker_c(file)\n",
        "        else:\n",
        "            bert_tag_sentence(file)\n",
        "    \n",
        "\n",
        "    elif model == 2:\n",
        "        print(\"Select a method:\")\n",
        "        print(\"1.) Entity Marker A\")\n",
        "        print(\"2.) Entity Marker B\")\n",
        "        print(\"3.) Entity Marker C\")\n",
        "        print(\"4.) Tag Sentence\")\n",
        "\n",
        "        method = int(input())\n",
        "\n",
        "        if method == 1:\n",
        "            roberta_entity_marker_a(file)\n",
        "        elif method == 2:\n",
        "            roberta_entity_marker_b(file)\n",
        "        elif method == 3:\n",
        "            roberta_entity_marker_c(file)\n",
        "        else:\n",
        "            roberta_tag_sentence(file)\n",
        "\n",
        "    else:\n",
        "        print(\"Please select 1 or 2.\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}